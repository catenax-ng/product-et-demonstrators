# Differential Privacy

## Introduction
Data is a valuable resource that might contain private information, as a user name, a phone number or a personal identification number. Additionally, it contains some explicit information that can be found by processing the data, like some design solutions. There is a growing concern about protecting the privacy, making it hard to gain any useful information from the data even sharing the data and gaining access to it.

Differential privacy is a set of techniques and mathematical guarantees that provide a strong level of privacy protection for the collected data, even if the information is implicit present in the dataset or not.

This technique allows organizations to collect and use data in a responsible and ethical way, without compromising the privacy of individuals. This concept is widely used in many fields such as healthcare, finance, and social media.

## Technical Information
Differential privacy involves adding random noise to the data in a controlled manner. There are multiple types of methodologies to apply.

### Participant Roles

### Building Blocks

## Evaluation
In this section we will be comparing the performance of Differential Privacy solutions in protecting the data while still allowing for useful data analysis.

### Advantages
1.	Privacy protection: Differential privacy provides a strong guarantee of privacy keeping data anonymized.
2.	Transparency: Differential privacy allows for the release of data without revealing sensitive information about individuals.
3.	Flexibility: Differential privacy can be applied to a wide variety of data types and use cases.
4.	Comparability: Differential privacy allows for the comparison of data from different sources without compromising privacy.
5.	It allows the owners of the data to control the trade-off between privacy and utility of it.

### Drawbacks
1.	High computational cost: Differential privacy algorithms can be computationally expensive, which can make them impractical for large datasets.
2.	High noise: Differential privacy algorithms is based on adding noise to the data, which can make it difficult to obtain accurate results.
3.	Limited applicability: Differential privacy may not be suitable for all types of data or use cases, and its effectiveness can depend on the specific characteristics of the data and the specific algorithm used.

## Technological Readiness Level